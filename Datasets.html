<!DOCTYPE html>
<html lang="en">
    
 
<head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
		<link rel="icon" href="img/logo.png">
    <title>Project</title>

    <!-- Bootstrap -->
    <link href="css/bootstrap.css" rel="stylesheet">
  
    <link rel="stylesheet" type="text/css" href="css/style.css">

      
        <link href="assets/css/font-awesome.min.css" rel="stylesheet">
        
        <link href="assets/css/owl.carousel.css" rel="stylesheet">
        <link href="assets/css/fancybox/jquery.fancybox.css" rel="stylesheet">
        <link href="assets/css/style.css" rel="stylesheet">
       
        
    </head>

    <body><header>
       
        <nav class="navbar navbar-default" style="background:#3399FF;color:#fff">
          <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header" >
              <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
				
              </button>
              <a class="navbar-brand" href="index.html"><img src="img/logo.png" class="img-responsive"></a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
              
              <ul class="nav navbar-nav navbar-right">
                <li><a href="index.html"><b><font color=#003366>Home</font></b></a></li>
				<li><a href="People.html"><b><font color=#003366>People</font></b></a></li>
                <li><a href="proj.html" ><b><font color=#003366>Research</font></b></a></li>
                <li><a style="background:#003366;color:#fff"  href="#"><b>Datasets</b></a></li>
				<li><a href="Project.html" ><b><font color=#003366>Project</font></b></a></li>
				<li><a href="publication.html" ><b><font color=#003366>Publications</font></b></a></li>
				<li><a href="index.html#footer"><b><font color=#003366>Contact Us</font></a></li>
                
              </ul>
            </div><!-- /.navbar-collapse -->
          </div><!-- /.container-fluid -->
        </nav>
    </header>

        <div class="container-fluid">
            



                    <!-- START ABOUT SECTION-->
                    <section id="about" class="section wow fadeInUpBig">
								
                     <section id="portfolio" class="section wow fadeInUp">
                        <div class="container-section">
                            <div class="row">
                                <div class="section-title">
                                    <h4>MOR-UAV Dataset</h4>
                                </div>
                            </div>
                                    
                            
											   
											   <h5>
											   The MOR-UAV dataset consists of 30 video sequences which are collected from multiple video recordings captured
with a UAV platform at a number of locations in highways, flyovers, traffic intersections, urban areas, agricultural regions, etc. These videos represent various scenarios including occlusion, nighttime, weather changes, camera motion, changing altitudes, different camera views, and angles. The videos are recorded at 30 frames per second (fps) and the resolution varies from 1280 × 720 to 1920 × 1080. The average, min, max lengths of the sequences are 364 .93 , 64 and 1 , 146 respectively. About 10, 948 frames in the MOR-UAV dataset are annotated with approximately 89, 783 bounding boxes representing moving vehicles. These vehicles are categorized into two classes: car (80 , 340 bounding boxes) and heavy vehicles (9 , 443 bounding boxes). The average, min, max lengths of the bounding box heights are 29.011, 6, 181, respectively. Similarly, average, min, max lengths of the bounding box widths are 17.641, 6, 106, respectively. We resize all the video frames in MOR-UAV dataset to 608 × 608 × 3 for a uniform setting in training and evaluation.

											   </h5>
											   <a class="profile-img" href="#"><img src="assets/images/MOR.png" width="100%" height="350" alt="image"></a>
                                               </h5> 

											  <br><br>
								
                                
                            
 <div class="row">
                                <div class="section-title">
                                    <h4>CDNet-MotionRec Dataset</h4>
                                </div>
                            </div>
                                    
                            
											   
											   <h5>
											   Due to lack of available benchmark datasets with labelled bounding boxes for moving object recognition (MOR), we created a new set of ground truths
by annotating 42,614 objects (14,814 cars and 27,800 person) in 24,923 video frames from CDNet 2014. We selected 16
video sequences having 21,717 frames and 38,827 objects (13,442 cars and 25,385 person) for training. For testing, 3 video
sequences with 3,206 frame and 3,787 objects (1 ,372 cars and 2,415 person) were chosen. We created axis-aligned
bounding box annotations for moving object instances in all the frames. Since, there has been no previous attempt to
perform such task, we defined our own train and test divisions for qualitative and quantitative evaluation. All the video
frames are reshaped into 608x608 for uniform training and evaluation. For more details, refer to the paper, 1. <a href="http://openaccess.thecvf.com/content_WACV_2020/html/Mandal_MotionRec_A_Unified_Deep_Framework_for_Moving_Object_Recognition_WACV_2020_paper.html"target="_blank">"MotionRec: A Unified Deep Framework for Moving Object Recognition,"</a> 
IEEE Winter Conference on Applications of Computer Vision (WACV-2020), US, 2020.
											   </h5>
											   <a class="profile-img" href="#"><img src="assets/images/CDNET.png" width="100%" height="350" alt="image"></a>
                                               </h5> 

											  <br><br>
								
                                
                            
 <div class="row">
                                <div class="section-title">
                                    <h4>ABD Dataset</h4>
                                </div>
                            </div>
                                    
                            
											   
											   <h5>
											   We collected around 2,000 new aerial images from online sources and generated a new dataset named
airborne dataset (ABD) by annotating approximately 42,408 objects. The objects were annotated with
four different classes: car (33,170), heavy vehicle (6,407), plane (743) and boat (2,088). The dataset
consists of a variety of scene including urban and residential areas, river banks, industrial aeras,
agricultural regions, bushes, railway tracks, traffic, country roads, airports, etc. References: 
1. <a href="https://ieeexplore.ieee.org/document/8755462" target="_blank"> “AVDNet: 
A Small-Sized Vehicle Detection Network for Aerial Visual Data,” </a> IEEE Geoscience and Remote Sensing Letters, vol. 17, no. 3 2020;
2. <a href="https://ieeexplore.ieee.org/document/8803262"target="_blank">"SSSDET: Simple Short and Shallow Network for Resource 
Efficient Vehicle Detection in Aerial Scenes,"</a> 26th IEEE International Conference on Image Processing (ICIP-2019), Taipei, Taiwan, 2019.
											   </h5>
										 	   <a class="profile-img" href="#"><img src="assets/images/ABD.png" width="100%" height="350" alt="image"></a>
                                               </h5> 

											  <br><br>
								
                                
                            

 <div class="row">
                                <div class="section-title">
                                    <h4>AnoVIL Anomaly Dataset</h4>
                                </div>
                            </div>
                                    
                            
											   
											   <h5>
											   A custom dataset was generated in a staged/controlled environment. We shot from four strategically placed cameras 
												simultaneously to capture multiple views of same scene. The videos were recorded at four different locations in different times
												of the day. The scenes involve normal data, fight happening in different scenarios, snatching, kidnapping etc.
												Scenes were shot indoor/outdoor, in natural light-artificial light, low light as well to cover illumination changes. The videos were recorded
												from varied distances to capture subjects with varying size. Post processing yielded usable clips of approx. 90 minutes (90x60x30x4= 648000 frames).
												Snippet for the same are depicted in the figure.
											   </h5>
											   <a class="profile-img" href="#"><img src="assets/images/ds2.JPG" width="100%" height="350" alt="image"></a>
                                               </h5> 

											  <br><br>
								
                                
                            

                        
                    </section>
                    <!-- END ABOUT SECTION-->

					
                    

       
</html>
