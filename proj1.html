<!DOCTYPE html>
<html lang="en">
    
 
<head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
		<link rel="icon" href="img/logo.png">
    <title>Project</title>

    <!-- Bootstrap -->
    <link href="css/bootstrap.css" rel="stylesheet">
  
    <link rel="stylesheet" type="text/css" href="css/style.css">

      
        <link href="assets/css/font-awesome.min.css" rel="stylesheet">
        
        <link href="assets/css/owl.carousel.css" rel="stylesheet">
        <link href="assets/css/fancybox/jquery.fancybox.css" rel="stylesheet">
        <link href="assets/css/style.css" rel="stylesheet">
       
        
    </head>

    <body><header>
       
        <nav class="navbar navbar-default">
          <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
              <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
				
              </button>
              <a class="navbar-brand" href="#"><img src="img/logo.png" class="img-responsive"></a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
              
              <ul class="nav navbar-nav navbar-right">
                <li><a href="index.html">Home</a></li>
				<li><a href="faculty.html">Instructor</a></li>
				<li><a href="phd.html">Students</a></li>
				<li><a href="proj.html">Research</a></li>
                <li><a href="#" style="background:#555;color:#fff">Project</a></li>
				<li><a href="publication.html" >Publications</a></li>
				<li><a href="index.html#footer">Contact Us</a></li>
                
              </ul>
            </div><!-- /.navbar-collapse -->
          </div><!-- /.container-fluid -->
        </nav>
    </header>
        
        <div class="container-fluid">
		
<!-- START PORTFOLIO SECTION-->
									
                    <section id="portfolio" class="section wow fadeInUp">
                        <div class="container-section">
                            
                            <div class="row">
                                <div class="grid">
                                    
                                    <div class="col-lg-12 col-md-12 col-sm-12">
                                    
                                    
									<div class="col-lg-12 col-md-12 col-sm-12">
										<h3 style="color:black">Project Title: Timestamp aware Aberrant Detection and Analysis 
										in Big Visual Data using Deep Learning Architecture</h3>
									    <h5 style="color:black">Funding Agency: Science and Engineering Research Board, Department of Science and Technology (SERB-DST, 2018)</h5>
										<h5 style="color:black">Principal Investigator: Dr. Santosh Kumar Vipparthi</h5>
										<h5 style="color:black">JRF/Ph.D. Scholar: Kuldeep Marotirao Biradar </h5>
										<h5>
										The proposed system removes the onus of detecting aberrance situations from the manual operator;
										and rather, places it on the video surveillance system.
										“The present technologies are fails to recognize aberration in video sequences. These aberrances
										occur over a small-time window. Thus, recognizing with its timeframe from a big visual data is really
										challenging task”. Hence, “our focus is on problems, where we are given a set of nominal training
										videos samples. Based on these samples need to determine whether or not a test video contains an
										aberration and what instant it occurs”. Similarly, “we aim to significantly reduce the time and human
										effort by automating the task and improving the accuracy by recognizing aberrances with its
										timestamp”. Further, “exploit the aberrance activity of the object by modeling the rich motion
										patterns in selected region, effectively capturing the underlying intrinsic structure they form in the
										video”.




										This system can be applied in various areas such as security systems, intelligent agencies,
										banks, department stores, traffic monitoring on highway, airport terminal check-in, sports, medical
										field, and robotics etc.
										</h5>
                                    </div>
									</div>
									        <div class="container-fluid">
											<div class="col-lg-12 col-md-col-sm-12">
                                        <figure class="effect-winston wow fadeInUp">

                                            

                                            <img src="assets/images/work/proj.GIF" alt="img" height="300" width="5"/>
                                            			
                                        </figure>
										
                                    </div>
	<!-- START PORTFOLIO SECTION-->
                    <section id="portfolio" class="section wow fadeInUp">
                        <div class="container-section">
                            <div class="row">
                                <div class="section-title">
                                    <h4>New Anomaly Dataset</h4>
                                </div>
                            </div>
                            <div class="row">
                                <div class="grid">
                                    
                                    <div class="col-lg-12 col-md-12 col-sm-12">
									<h5 >A custom dataset was generated in a staged/controlled environment. We shot from four strategically placed cameras 
simultaneously to capture multiple views of same scene. The videos were recorded at four different locations in different times
of the day. The scenes involve normal data, fight happening in different scenarios, snatching, kidnapping etc.
Scenes were shot indoor/outdoor, in natural light-artificial light, low light as well to cover illumination changes. The videos were recorded
from varied distances to capture subjects with varying size. Post processing yielded usable clips of approx. 90 minutes (90x60x30x4= 648000 frames).
Snippet for the same are depicted in the figure.</h5>
									<div class="container-fluid">
											<div class="col-lg-12 col-md-col-sm-12">
                                        <figure class="effect-winston wow fadeInUp">

                                            

                                            <img src="assets/images/ds2.jpg" alt="img" height="300" width="5"/>
                                            			
                                        </figure>
										
                                    </div>
								
	 </div>
									</div>
                                </div>
                            </div>
                        </div>
                    </section>								
									
<!-- START PORTFOLIO SECTION-->
                    <section id="portfolio" class="section wow fadeInUp">
                        <div class="container-section">
                            <div class="row">
                                <div class="section-title">
                                    <h4>Publications</h4>
                                </div>
                            </div>
                            <div class="row">
                                <div class="grid">
                                    
                                    <div class="col-lg-12 col-md-12 col-sm-12">

									



<b>1.</b>	
    Murari Mandal, Monu Verma, Sonakshi Mathur, <b>Santosh Vipparthi</b>, Subrahmanyam Murala, Kranthi Deveerasetty, 
	<a href="https://digital-library.theiet.org/content/journals/10.1049/iet-ipr.2018.5683"target="_blank">"RADAP: Regional Adaptive Affinitive Patterns with 
	Logical Operators for Facial Expression Recognition,"</a>  IET Image Processing, 2019(Impact Factor 1.40).
     </h5>                               	
	<h5 style="color:black">	

	<b>2.</b>Murari Mandal,<b> Santosh Kumar Vipparthi</b>, Mallika Chaudhary, Subramanian Murala, Anil Balaji Gonde,
	S. K. Nagar,<a href="https://digital-library.theiet.org/content/journals/10.1049/iet-cvi.2018.5206"target="_blank"> ANTIC: ANTithetic Isomeric Cluster Patterns for Medical Image Retrieval and Change Detection,
	IET Computer Vision</a>, (IEEE, IET), (2018) (Impact Factor 1.087).
</h5>



<h5 style="color:black">	
	<b>3.</b>Murari Mandal, Prafulla Saxena, <b>Santosh Kumar Vipparthi</b>, Subrahmanyam Murala, 
	<a href="https://arxiv.org/abs/1804.07008"target="_blank">CANDID: Robust Change Dynamics and Deterministic Update Policy for Dynamic Background Subtraction, 
	IEEE 24th International Conference on Pattern Recognition (ICPR)</a>, Beijing, China (IEEE) (2018).

</h5>
<h5 style="color:black">	
<b>4.</b>Monu Verma, Jaspreet Kaur Bhui, <b>Santosh Kumar Vipparthi</b>,
 Girdhari Singh, EXPERTNet: Exigent Features Preservative Network for Facial 
 Expression Recogntion. ACM 11th International Conference on Computer Vision, Graphics and
 Image Processing (ICVGIP), Hyderabad, India (2018).
</h5>

<h5 style="color:black">	
<b>5.</b>Kuldeep Biradar, Sachin Dube, Santosh Kumar Vipparthi,<a href="#"target="_blank"> “DEAREST: Deep Convolutional
Aberrant Behaviour Detection in Real world Scenario,” </a>13th international conference on
industrial and information system, 2018.

	
</h5>

<h5 style="color:black">	
<b>6.</b>Monu Verma, Prafulla Saxena, <b>Santosh Kumar Vipparthi</b>, Gridhari Singh, 
<a href="https://arxiv.org/abs/1807.09154"target="_blank">QUEST: Quadriletral Senary bit Pattern for Facial Expression Recognition,
 IEEE International Conference on Systems, Man, and Cybernatics</a>, Miyazaki, Japan, (IEEE) (2018).
</h5>




										<h5>
										
										</h5>
                                    </div>
									</div>
									
									
									
									
									
                                    
                                    






                                </div>
                            </div>
                        </div>
                    </section>
									
									






                                </div>
                            </div>
                        </div>
                    </section>
					
                    <!-- END PORTFOLIO SECTION-->
</body>
</html>
